[Causal Inference in Statistics : A primer](https://www.amazon.com/Causal-Inference-Statistics-Judea-Pearl/dp/1119186846)
를 읽고 내용을 간단히 정리한다.

**Ch1. Preliminaries: Statistical and Causal Models**

# 1. Why Study Causation

왜 인과관계에 대해서 공부해야 할까?

데이터를 이해하고 적절한 선택을 하기 위해서는 인과관계에 대해 공부해야 한다.
특히 원인이 결과에 어떻게, 왜 영향을 미치는 것인지 이해할 필요가 있다.
예를 들어, 말라리아에 대해서 이해하려면 옛날 사람들이 믿었던 대로 나쁜 공기 (mal-air) 가 아니라 모기를 통해 전파된다는 사실을 알아야 한다.
그래야 산소 마스크 대신 모기 퇴치제를 챙겨 대비할 수 있다.

그렇다면 기존의 "통계" 라는 것들을 놔두고 왜 "인과관계"라는 주제를 따로 분리시킨 것일까?

엄밀하게 보면 인과관계에 대한 추론은 기존의 통계와는 조금 다르다.
통계학에 인과관계에 대한 내용이 추가되면 기존의 방법론만으로는 다룰 수 없었던 문제들을 다룰 수 있다.

전통적인 통계학에서 왜 인과 관계를 다루어야 하는지 살펴보기 위해, 통계학의 한 유명한 문제를 살펴보자.

# 2. Simpson's Paradox

심슨의 역설은 전체 데이터에서 보이는 경향이 세부 그룹 레벨에서는 정반대로 보이는 현상을 말한다.
아래 데이터를 보면 남성과 여성 그룹 모두 약을 투약한 환자 그룹의 효과가 좋은 것으로 나타났지만, 전체 데이터로 합치면 약을 투약하지 않은 그룹의 효과가 더 좋은 것으로 보인다.

|      | Drug               | No Drug             |
|:----:|--------------------|---------------------|
| 남성 | **81 / 87 (93%)**   | 234 / 270 (87%)     |
| 여성 | **192 / 263 (73%)** | 55 / 80 (69%)       |
| 전체 | 273 / 350 (78%)     | **289 / 350 (83%)** |

위 결과를 보고 특정 환자에게 약을 처방하는 것이 더 나은지 판단할 수 있을까?

단순한 통계 수치 만으로는 결론을 내릴 수 없다.
약이 환자에게 도움이 될지 아닌지를 알기 위해서는 데이터 뒤에 있는 스토리, 즉 현재 결과로 이어지는 인과 과정을 이해해야 한다.
예를 들면, 여성 호르몬이 회복에 악영향을 미친다는 것을 알고 있다고 생각해보자.
게다가 데이터를 보니 여성이 남성에 비해 약을 투약한 사람의 수가 훨씬 많다.
그렇다면 특정 환자가 여성이라는 사실이 "약을 먹는 것"과 "회복되지 않는 것"의 공통적인 원인이라는 점을 알 수 있다.
따라서 효과를 측정하기 위해서는 같은 성별끼리 비교해야 한다.

통계학 교과서에서는 상관관계가 인과관계를 의미하지 않는다고 경고한다.
따라서 데이터만으로부터 인과 관계의 스토리를 풀어가는 통계적 기법은 제시하지 않는다.
하지만 통계학자들은 이러한 인과관계적 가설을 바탕으로 데이터를 해석한다.
사실 위에서 살펴본 심슨의 역설 문제는 치료 여부가 성별에 영향을 줄 수 없다는 가정을 바탕으로 한다.
만약 영향을 줄 수 있다면, 여기에는 역설이 존재할 여지가 없다.
"치료 여부가 성별에 영향을 줄 수 없다" 라는 가정은 당연한 것처럼 보이지만 테스트할 수 있는 방법은 없다.
또, 일반적인 통계학에서는 이것을 수학적으로 표현할 수 있는 방법이 없다.

하지만 추가적인 정의를 통해 이러한 관계를 표현할 수 있다.
인과 관계의 스토리를 엄밀하게 표현하고 이해하기 위해 다음과 같은 네 가지 요소가 필요하다.

1. "인과"에 대한 정의
2. 인과관계 가정을 엄밀하게 표현하기 위한 방법
3. 인과관계 모형에 데이터의 변수들을 연결하는 방법
4. 모형과 데이터에 포함된 인과관계 가정들을 바탕으로 결론을 이끌어내기 위한 방법

# 3 ~ 4 : skip

# 5. Structural Causal Models

## 5.1 Modeling Causal Assumptions

인과관계 문제를 엄밀하게 다루기 위해 구조적 인과 모형 (Structural Causal Model, SCM) 이라는 개념을 살펴볼 것이다.
이를 통해 각 변수들이 어떻게 상호작용하는지 표현할 수 있다.
구조적 인과 모형은 두 가지 종류의 변수 U와 V, 그리고 다른 변수들의 값을 바탕으로 각각의 변수에 값을 부여하는 함수 f 로 구성된다.
이제 인과관계에 대한 정의를 확장시켜보자.

> 변수 Y의 값에 영향을 주는 함수에 변수 X가 나타난다면, X는 Y의 직접적인 원인 (Direct Cause) 이다.
> 만약 X가 Y 또는 Y의 원인들과 직접적인 원인 (Direct Cause) 관계에 있다면, X는 Y의 원인이다.

- 변수 U는 모형 바깥에 있는 외생변수를 말한다. 이러한 변수들에 대해서는 왜 발생했는지 원인을 따지지 않는다.
- 변수 V는 모형 내부에 있는 내생변수를 말한다. 모든 내생변수들은 적어도 하나의 외생변수로부터 파생된 값이다.
- 만약 모든 외생변수들의 값과 함수 f를 알 수 있다면 모든 내생변수들의 값도 계산할 수 있다.

모든 SCM은 그래프 인과 모형 (Graphical Causal Model) 과 관련이 있다.
특히 그 중에서도 DAG (Directed Acyclic Graphs) 의 형태로 다룰 것이다.
변수 X가 Y의 자식 노드라면 Y는 X의 direct cause다.
X가 Y의 자손 노드 중 하나라면 Y는 X의 가능성있는 원인 중 하나일 것이다.

그래피컬 모형은 SCM에 비해 더 적은 정보를 담고 있지만 정량화하기 어려운 변수들도 쉽게 표현할 수 있다는 장점이 있다.
물론 그래프를 그리는 대신 일부 정보만 명시된 형태의 SCM을 사용할 수도 있다.

```
V = {Height, Sex, Performance} , U = {U1, U2, U3}, F = {f1, f2}

Sex = U1
Height = f1(Sex, U2)
Performance = f2(Height, Sex, U3)
```

여기서 U는 이름을 붙일 필요는 없지만 V 변수들에 영향을 미친다.
U 요인들은 "오차 항목" (error terms) 또는 "생략된 요인" (omitted factors) 이라고도 불린다.
이것들은 우리가 관찰하는 것에 대한 알려지지 않은 외부적인 원인을 나타낸다.

그래피컬 모형은 위와 같이 제한적으로 명시된 SCM보다 직관적으로 표현할 수 있다.
제공하는 정보의 양이 동일하더라도 훨씬 이해하기 쉽게 보여줄 수 있다는 것이 그래피컬 모형의 장점이다.

## 5.2 Product Decomposition

그래피컬 모형의 또 다른 장점은 결합 확률분포를 효과적으로 표현할 수 있다는 점이다.
지금까지 우리는 두 가지 방식으로 결합 확률분포를 표현해왔다.

1. 표를 사용하여 모든 경우의 수에 대한 확률을 계산해둔다
    - 이해하기 쉽지만, 변수가 많아질수록 필요한 공간이 기하급수적으로 늘어난다
    - 예를 들면, 10개의 binary 변수가 있다면 1024 row가 필요하다
2. fully specified SCM을 통해 표현한다
    - 변수간의 관계와 오차항의 확률을 안다면 모든 결합 확률의 분포를 알 수 있다
    - 하지만 모형의 모든 항목들을 명시하기 어려울 때가 많다
        - 한 변수가 다른 변수의 원인이라는 것을 알아도, 구체적인 식을 통해 표현하기는 어렵다
        - 오차항의 분포를 모를 때도 있다

그래피컬 모형을 사용하면 이러한 문제를 해결하는데 도움이 된다.

비순환(acyclic) 그래프의 경우, 모형의 결합 확률 분포를 조건부 확률분포들의 곱으로 표현할 수 있다.
다음과 같은 식으로 나타낼 수 있다.

```
P(x_1, x_2, ... , x_n) = Prod_i( P(x_i | pa_i )

where pa_i = 변수 x_i의 부모 노드의 값
```

예를 들어, 간단한 그래프 X -> Y -> Z 는 다음과 같이 나타낼 수 있다.

```
P(X=x, Y=y, Z=z) = P(X=x) * P(Y=y | X=x) * P(Z=z | Y=y)
```

가능한 모든 (x, y, z) 의 조합에 대한 확률값을 구할 필요가 없다. X, (Y|X), (Z|Y) 에 대한 확률값을 구해서 곱하면 된다.
