# Practical Bayesian Optimization of Machine Learning Algorithms

[PR-080](https://www.youtube.com/watch?v=MnHCe8tGjQ8)

## (0) Introduction

* 하이퍼 파라미터 최적화
    * 한 번 트레이닝 하는 것도 굉장히 많은 시간을 필요로 한다
    * 따라서 일반적인 머신러닝 최적화 방법을 적용할 수는 없다
    * 반복 횟수를 줄이면서 최적화를 할 수 있는 방법이 없을까?
    * 최근 각광받고 있는 방법은 Bayesian Optimization
* Bayesian Optimization
    * 사용한지 이미 몇십년이 됐지만 머신러닝에는 적용하지 못하고 있었음
    * 2012년에 해당 논문에서 기존 BO의 몇 가지 문제점을 개선하여 하이퍼 파라미터 최적화에 활용

## (1) Tuning ML Hyperparameters

* 최적의 하이퍼 파라미터를 모를 경우에는 :
    * 일단 기본값으로 두고 실험을 수행하고 Loss Function 값을 재본다
    * 결과가 만족스럽지 않다면 하이퍼 파라미터 값을 바꾸어가면서 실험을 반복한다
* 하이퍼 파라미터 최적화가 중요한 이유는 무엇일까?
    * 튜닝을 통해 큰 성능 향상을 얻을 수 있다
    * 최적의 파라미터를 찾아내는 정해진 방법이 없다 (Art에 가깝다?)
    * 논문의 신뢰성에도 큰 영향을 주었다
        * 다른 사람의 논문을 재현할 때는 하이퍼 파라미터를 대충 계산하고, 내 논문을 쓸 때는 공들여서 구하는 등
    * 머신러닝 전문가가 아닌 사람이 접했을 때 어려움을 느끼는 부분이다
* 하이퍼 파라미터 최적화 문제
    * Validation Set의 데이터를 우리가 만든 머신러닝 알고리즘에 넣어서 Loss Function 값을 구한다
    * Loss 값의 평균 또는 전체합을 최소화하는 파라미터가 바로 우리가 찾는 최적의 하이퍼 파라미터
* 방법이 없으니 보통 Grid Search나 Random Search를 사용했다
    * Grid Search
        * 가능한 모든 파라미터 조합을 테스트한다
            * 두 가지 파라미터에 각각 세 가지 값이 있다면 3 x 3 = 9 가지 조합
        * 바꾸어도 성능에 큰 변화가 없는 파라미터가 있다면, 해당 파라미터를 계속 바꾸면서 실험하는 것은 시간 낭비다
            * 하지만 낭비가 발생할지 여부를 미리 알 수 없다..
    * Random Search
        * 랜덤한 파라미터 조합으로 실험한다
    * Grad Student Descent
        * 논문의 저자들이 (개그로..?) 적어놓은 것
        * 실험자(대학원생)들이 잘 될 것 같은 파라미터를 몇 개 찍어서 진행
        * 재현성의 문제가 있다
        * 실험하는 사람의 주관에 의해 달라질 우려가 있음
* 새로운 방법이 없을까??
