# 다양한 PCA / 차원축소 알고리즘

* 점진적 PCA (Incremental PCA, IPCA)
    * 훈련 세트를 미니배치로 나눈 뒤 IPCA 알고리즘에 하나씩 주입한다
    * 훈련 세트가 크거나 온라인으로 PCA를 적용할 때 유리한 방식

* 랜덤 PCA (Randomized PCA)
    * 확률적인 방식으로 첫 d개의 주성분에 대한 근사값을 빠르게 찾는다

* 커널 PCA (kernel PCA, kPCA)
    * 커널트릭을 이용한 비선형 투영 방식의 차원축소
    * 투영된 후 샘플의 군집을 유지하거나, 꼬인 매니폴드를 풀어야 할 때 유용하다
    * 좋은 커널과 하이퍼파라미터에 대한 명확한 기준은 없음

* 지역 선형 임베딩 (Locally Linear Embedding, LLE)
    * 투영에 의존하지 않는 매니폴드 학습법
        * 잡음이 많지 않은 경우, 데이터 양이 많지 않은 경우 잘 작동한다
    * 1) 각 훈련 샘플이 가장 가까운 이웃에 얼마나 선형적으로 연결되어 있는지 측정한다
    * 2) 국부적인 관계가 잘 유지되는 저차원 표현을 찾는다

* 다차원 스케일링 (MDS)
    * 샘플간의 거리를 보존하면서 차원을 축소한다

* Isomap
    * 각 샘플을 가장 가까운 이웃과 연결하는 방식으로 그래프를 구성한다
    * 각 샘플의 지오데식 거리를 유지하도록 차원을 축소한다

* t-SNE
    * 비슷한 샘플은 가까이, 비슷하지 않은 샘플은 멀어지도록 차원을 축소한다
    * 주로 시각화에 사용. 특히 고차원 공간의 군집을 시각화하는데 많이 사용한다

* 선형 판별 분석 (LDA)
    * 사실은 분류 알고리즘
    * 훈련과정에서 클래스 사이를 가장 잘 구분하는 축을 학습한다 (초평면을 정의하는데 쓸 수 있음)
    * 투영을 통해 클래스 간의 거리를 최대한 유지시키려 한다 ( 다른 분류 모형을 쓰기 전에 사용하기 좋다 )
